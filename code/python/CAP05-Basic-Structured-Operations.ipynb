{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Structured Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.shell import spark\n",
    "\n",
    "# Create a Dataframe\n",
    "df = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "    .load(\"/datasets/flight-data/json/2015-summary.json\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing schema in Dataframe\n",
    "spark.read \\\n",
    "    .format(\"json\") \\\n",
    "    .load(\"/datasets/flight-data/json/2015-summary.json\") \\\n",
    "    .schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "# Exploring Spark's complex types\n",
    "myManualSchema = StructType([\n",
    "    StructField(\"DEST_COUNTRY_NAME\", StringType(), True),\n",
    "    StructField(\"ORIGIN_COUNTRY_NAME\", StringType(), True),\n",
    "    StructField(\"count\", LongType(), False, metadata={\"hello\":\"world\"})\n",
    "])\n",
    "\n",
    "df = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "    .schema(myManualSchema) \\\n",
    "    .load(\"/datasets/flight-data/json/2015-summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, column\n",
    "col(\"someColumnName\")\n",
    "column(\"someColumnName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns as expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "expr(\"(((someCol + 5) * 200) - 6) < otherCol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "myRow = Row(\"Hello\", None, 1, False)\n",
    "\n",
    "print(myRow[0])\n",
    "print(myRow[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "    .schema(myManualSchema) \\\n",
    "    .load(\"/datasets/flight-data/json/2015-summary.json\")\n",
    "\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myManualSchema = StructType([\n",
    "    StructField(\"some\", StringType(), True),\n",
    "    StructField(\"col\", StringType(), True),\n",
    "    StructField(\"names\", LongType(), False)\n",
    "])\n",
    "\n",
    "myRow = Row(\"Hello\", None, 1)\n",
    "myDF = spark.createDataFrame([myRow], myManualSchema)\n",
    "myDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select and selectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\", \"ORIGIN_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col, column\n",
    "df.select(\n",
    "    expr(\"DEST_COUNTRY_NAME\"),\n",
    "    col(\"DEST_COUNTRY_NAME\"),\n",
    "    column(\"DEST_COUNTRY_NAME\")\n",
    ").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(expr(\"DEST_COUNTRY_NAME AS destination\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(expr(\"DEST_COUNTRY_NAME AS destination\").alias(\"DEST_COUNTRY_NAME\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr(\"DEST_COUNTRY_NAME as newColumnName\", \"DEST_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr(\n",
    "    \"*\", # all original columns\n",
    "    \"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr(\n",
    "    \"AVG(count)\",\n",
    "    \"COUNT(DISTINCT(DEST_COUNTRY_NAME))\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to Spark Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df.select(expr(\"*\"), lit(1).alias(\"One\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"numberOne\", lit(1)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"withinCountry\", expr(\"ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\", \"dest\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reserved Characters and Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithLongColName = df.withColumn(\n",
    "    'This Long Column-Name',\n",
    "    expr(\"ORIGIN_COUNTRY_NAME\")\n",
    ")\n",
    "\n",
    "dfWithLongColName.selectExpr(\n",
    "    \"`This Long Column-Name`\",\n",
    "    \"`This Long Column-Name` as `new col`\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithLongColName.select(col(\"This Long Column-Name\")).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"ORIGIN_COUNTRY_NAME\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithLongColName.drop(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Column's Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"count2\", col(\"count\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(col(\"count\") < 2).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(\"count < 2\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(col(\"count\") < 2) \\\n",
    "    .where(col(\"ORIGIN_COUNTRY_NAME\") != \"Croatia\") \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Unique Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\") \\\n",
    "    .distinct() \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"ORIGIN_COUNTRY_NAME\") \\\n",
    "    .distinct() \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5\n",
    "withReplacement = False\n",
    "fraction = 0.5\n",
    "df.sample(withReplacement, fraction, seed).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrames = df.randomSplit([0.25, 0.75], seed)\n",
    "dataFrames[0].count() > dataFrames[1].count() # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating and Appending Rows (Union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "schema = df.schema\n",
    "newRows = [\n",
    "    Row(\"New Country 1\", \"Other Country 1\", 5),\n",
    "    Row(\"New Country 2\", \"Other Country 3\", 1)\n",
    "]\n",
    "parallelizedRows = spark.sparkContext.parallelize(newRows)\n",
    "newDF = spark.createDataFrame(parallelizedRows, schema)\n",
    "\n",
    "df.union(newDF) \\\n",
    "    .where(col(\"count\") == 1) \\\n",
    "    .where(col(\"ORIGIN_COUNTRY_NAME\") != \"United States\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(\"count\").show(5)\n",
    "df.orderBy(\"count\", \"DEST_COUNTRY_NAME\").show(5)\n",
    "df.orderBy(col(\"count\"), col(\"DEST_COUNTRY_NAME\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, asc\n",
    "\n",
    "df.orderBy(expr(\"count desc\")).show(5)\n",
    "df.orderBy(col(\"count\").desc(), col(\"DEST_COUNTRY_NAME\").asc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read \\\n",
    "    .format(\"json\") \\\n",
    "    .load(\"/datasets/flight-data/json/*-summary.json\") \\\n",
    "    .sortWithinPartitions(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(expr(\"count desc\")).limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repartition and Coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()\n",
    "\n",
    "df.repartition(5)\n",
    "\n",
    "df.repartition(col(\"DEST_COUNTRY_NAME\"))\n",
    "\n",
    "df.repartition(5, col(\"DEST_COUNTRY_NAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(5, col(\"DEST_COUNTRY_NAME\")).coalesce(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting Rows to the Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectDF = df.limit(10)\n",
    "collectDF.take(5) # take works with an Integer count\n",
    "collectDF.show() # this prints it out nicely\n",
    "collectDF.show(5, False)\n",
    "collectDF.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
